{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U-nb_o5XjqkO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eier\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# Getting the right libraries -- ignore this part\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"ggplot\")\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "U16ds4_xj7v4"
   },
   "outputs": [],
   "source": [
    "# reading the data\n",
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('https://stanford.edu/~lodewijk/share/heart.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQRWAsoyj9tt",
    "outputId": "7a34c6e6-d048-4ca5-8f62-c082841eab65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n",
      "(303,)\n"
     ]
    }
   ],
   "source": [
    "# Extracting X and y\n",
    "X = np.array([x[:-1] for x in my_data])\n",
    "y = np.array([x[-1] for x in my_data])\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoUNQsMZj_Re",
    "outputId": "f2d01fe1-5a16-4a88-81bc-232281b79923"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236, 13)\n",
      "(67, 13)\n",
      "(236,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "# Partitioning into training and test\n",
    "np.random.seed(42)\n",
    "rnds = np.random.rand(303) > 0.2\n",
    "X_train = X[rnds]\n",
    "X_test = X[~rnds]\n",
    "y_train = y[rnds]\n",
    "y_test = y[~rnds]\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cXp_5qfo9SoO"
   },
   "outputs": [],
   "source": [
    "# HW Assignment (extra credit) \n",
    "\n",
    "# (a) Run SVM on X_train and y_train and report the accuracy on X_train and X_test (1.5% credit). Pick a value of C that give good results.\n",
    "# (b) Run QP as opposed to SVM and verify predictions are the same (1% credit). See https://www.cvxpy.org/ or  https://cvxopt.org/examples/tutorial/qp.html .\n",
    "#     Note that the parameter C may not cleanly correspond to 1/(2*lambda) because of randomness, so it is ok if the exact QP is not the same, but you should\n",
    "#     be able to get the predictions to match.\n",
    "#\n",
    "# FAQ 1: I don't know python. What should I do? Answer: you have most of what you need here or at cvxpy\n",
    "#\n",
    "# FAQ 2: Can I use another language? Answer: Yes, if you can find a QP solver. Just do part (b) and you will get the full 2.5%. \n",
    "#\n",
    "# FAQ 3: How much support can I expect?\n",
    "#          Answer: On the theory part, as much as you need\n",
    "#                  On the assignment: we will demo how to solve a QP using cvxpy at some point, but that's all the help you can expect.\n",
    "#\n",
    "# FAQ 4: How do I install numpy? Where do I get python? How do I install cvxpy or cvxopt?\n",
    "# Answer: Don't, don't and don't. Go to the colaboratory (https://colab.research.google.com) and start a new Python2 notebook, and then just import the libraries, e.g. on the first line in this notebook\n",
    "\n",
    "# FAQ 5: What should I submit? Answer: Please upload a pdf printout of your notebook. Include a link to your workbook (make it publicly viewable at least by Stanford accounts) in the pdf\n",
    "#\n",
    "# students who are struggling can catch up and students who want more challenging work can focus on the two modules.\n",
    "# Final Note: You can collaborate on getting cvxpy to work and on getting colaborotary and svm libraries to work, and on reading data, but not on the actual training and prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "From the ppt: \"Since this for this data set we our algorithm to be conservative (i.e., always correctly classify individuals with heart disease) we may want to modify our objective accordingly.\" \n",
    "\n",
    "Since we want to be conservative I have decided to use the recall/sensitivity as my objective. This is the fraction of positives that are correctly identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = np.arange(0.1, 10, 0.1) #Range of possible C values from 0.1 to 9.9.\n",
    "\n",
    "recall_scores = {} #Store the recall scores\n",
    "for i in param_grid: #Loop over all the possible values for C\n",
    "    svc = svm.SVC(C = i, kernel = \"linear\")\n",
    "    svc.fit(X_train,y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    recall_scores[i] = recall_score(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=6.7, kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = max(recall_scores, key = recall_scores.get)\n",
    "print(c)\n",
    "svc = svm.SVC(C = c, kernel = \"linear\")\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955223880597015\n",
      "0.8809523809523809\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(recall_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = len(X_train[0]) #Total number of features\n",
    "n = len(X_train) #Total number of data points/deltas\n",
    "\n",
    "m = sum(y_train)\n",
    "k = len(y_train)-m\n",
    "\n",
    "n_vars = 1 + d + n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07462686567164178\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2116e+02  5.4845e+02  2e+03  4e+00  7e+02\n",
      " 1:  2.7560e+02 -6.7976e+01  5e+02  5e-01  8e+01\n",
      " 2:  1.2672e+02  6.2471e+01  7e+01  6e-02  9e+00\n",
      " 3:  9.9202e+01  8.0291e+01  2e+01  1e-02  2e+00\n",
      " 4:  9.2562e+01  8.5883e+01  7e+00  4e-03  7e-01\n",
      " 5:  9.0739e+01  8.7598e+01  3e+00  1e-03  2e-01\n",
      " 6:  8.9823e+01  8.8203e+01  2e+00  3e-04  6e-02\n",
      " 7:  8.9127e+01  8.8756e+01  4e-01  6e-05  1e-02\n",
      " 8:  8.8985e+01  8.8870e+01  1e-01  1e-05  2e-03\n",
      " 9:  8.8931e+01  8.8915e+01  2e-02  1e-06  2e-04\n",
      "10:  8.8923e+01  8.8922e+01  1e-03  8e-08  1e-05\n",
      "11:  8.8922e+01  8.8922e+01  1e-05  8e-10  1e-07\n",
      "12:  8.8922e+01  8.8922e+01  1e-07  8e-12  1e-09\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "lmb = 1/(2*c)\n",
    "print(lmb)\n",
    "\n",
    "Q = []\n",
    "p = []\n",
    "\n",
    "for i in range(n_vars):\n",
    "    q_row = [0.0] * n_vars \n",
    "    if i <= d: \n",
    "        p.append(0.0)\n",
    "        if i <= 1:\n",
    "            q_row[i] = 2.0*lmb\n",
    "    else:\n",
    "        p.append(1.0)\n",
    "\n",
    "    Q.append(q_row)\n",
    "    \n",
    "G = []\n",
    "h = []\n",
    "for i in range(n):\n",
    "    if i < m:\n",
    "        h.append(-1.0)\n",
    "        h.append(0)\n",
    "        g1 = [1] + list(X_train[i]) + [0.0] * n\n",
    "        g1[1+d+i] = -1.0\n",
    "        g2 = [0.0] * n_vars\n",
    "        g2[1+d+i] = -1.0\n",
    "    else:\n",
    "        h.append(-1.0)\n",
    "        h.append(0)\n",
    "        g1 = [-1] + list(-X_train[i]) + [0.0] * n\n",
    "        g1[1+d+i] = -1.0\n",
    "        g2 = [0.0] * n_vars\n",
    "        g2[1+d+i] = -1.0\n",
    "    \n",
    "    G.append(g1)\n",
    "    G.append(g2)\n",
    "    \n",
    "solvers.options['show_progress']=True\n",
    "solution = solvers.qp(matrix(Q), matrix(p), matrix(G).trans(), matrix(h), verbose=True)\n",
    "\n",
    "betas_qp = np.array(solution['x'][1:14]).reshape(13)\n",
    "alpha_qp = solution['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656716417910447\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(X, alpha, betas):\n",
    "    y_pred = []\n",
    "    for i in range(len(X)):\n",
    "        val = alpha + np.dot(X[i], betas)\n",
    "        if val < 0:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "y_pred_qp = make_prediction(X_test, alpha_qp, betas_qp)\n",
    "\n",
    "print(accuracy_score(y_pred_qp, y_test))\n",
    "print(recall_score(y_pred_qp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(y_pred_qp-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see in the cell above, we have only two predictions that differ from the sklearn library and the quadratic programming version"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
